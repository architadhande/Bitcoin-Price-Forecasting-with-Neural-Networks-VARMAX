{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95836a3-837d-4da6-a442-5d42c06e7df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.5.3)\n",
      "Collecting keras\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: statsmodels in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.14.4)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.37.36)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras) (13.9.4)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras) (3.12.1)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras) (21.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.36 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.37.36)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.11.4)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.38.0,>=1.37.36->boto3) (2.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->keras) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optree->keras) (4.13.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m146.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (397 kB)\n",
      "Installing collected packages: namex, optree, ml-dtypes, absl-py, keras\n",
      "Successfully installed absl-py-2.2.2 keras-3.9.2 ml-dtypes-0.5.1 namex-0.0.9 optree-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas keras scikit-learn statsmodels boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a491a331-e047-4d8b-b72c-1859783efbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Price      Open      High       Low     Vol. Change %\n",
      "0  03/24/2024  67,211.9  64,036.5  67,587.8  63,812.9   65.59K    4.96%\n",
      "1  03/23/2024  64,037.8  63,785.6  65,972.4  63,074.9   35.11K    0.40%\n",
      "2  03/22/2024  63,785.5  65,501.5  66,633.3  62,328.3   72.43K   -2.62%\n",
      "3  03/21/2024  65,503.8  67,860.0  68,161.7  64,616.1   75.26K   -3.46%\n",
      "4  03/20/2024  67,854.0  62,046.8  68,029.5  60,850.9  133.53K    9.35%\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the S3 bucket and the key (file path) for the file you want to download\n",
    "bucket_name = 'crypto-prediction-project'\n",
    "file_key = 'data/Bitcoin Historical Data.csv'\n",
    "local_file_name = 'bitcoin_data.csv'\n",
    "\n",
    "# Download data from the S3 bucket to the local system\n",
    "s3.download_file(bucket_name, file_key, local_file_name)\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv(local_file_name)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5fbfb2-a2e2-4a80-af6f-e5dcd81643f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.2.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (78.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->tensorflow) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, markdown, grpcio, gast, astunparse, tensorboard, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 grpcio-1.71.0 libclang-18.1.1 markdown-3.8 opt-einsum-3.4.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcdf50f2-03f2-4425-b249-e38aae64068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 05:03:37.539011: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0186\n",
      "Epoch 2/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 5.3531e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - loss: 4.6144e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 3.6696e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 5.3785e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 3.5812e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 3.1768e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 4.8225e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 2.6213e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 2.4186e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "# Assuming 'df' is already loaded with your dataset (e.g., from S3 or CSV)\n",
    "\n",
    "# Remove commas from the 'Price' column and convert to float\n",
    "df['Price'] = df['Price'].replace({',': ''}, regex=True).astype(float)\n",
    "\n",
    "# Data preprocessing: Scale the features and labels\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[['Price']].values)\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data, test_data = scaled_data[:train_size], scaled_data[train_size:]\n",
    "\n",
    "# Prepare data for LSTM (LSTM expects 3D input: [samples, timesteps, features])\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), 0])  # Features\n",
    "        y.append(data[i + time_step, 0])      # Label\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "time_step = 60  # Use previous 60 days to predict the next day\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "# Reshape inputs to be 3D [samples, time steps, features] for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))  # Output layer\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Save the model\n",
    "model.save('bitcoin_lstm_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e44ec86-1635-499b-a056-d90e7cabc176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999    0.1\n",
      "5000    0.1\n",
      "5001    0.1\n",
      "5002    0.1\n",
      "5003    0.1\n",
      "Name: predicted_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit an ARIMA model on 'Price' series\n",
    "model = sm.tsa.ARIMA(df['Price'], order=(1, 1, 1))  # (p,d,q) can be tuned\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Save the model\n",
    "model_fit.save('bitcoin_arima_model.pkl')\n",
    "\n",
    "# Forecast the next 5 values\n",
    "forecast = model_fit.forecast(steps=5)\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51bdc505-7da7-4a71-a090-f51d6ad6b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Get live data from an API (e.g., CoinGecko)\n",
    "    response = requests.get('https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd')\n",
    "    price = response.json()['bitcoin']['usd']\n",
    "    \n",
    "    # Call SageMaker endpoint for prediction\n",
    "    sagemaker_client = boto3.client('sagemaker-runtime')\n",
    "    endpoint_name = 'your-endpoint-name'\n",
    "    payload = f'{{\"price\": {price}}}'\n",
    "    \n",
    "    response = sagemaker_client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=payload)\n",
    "    \n",
    "    prediction = response['Body'].read().decode('utf-8')\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': prediction\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "351bf669-5b8a-4b86-9ed8-f74874b34208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Get live data from an API (e.g., CoinGecko)\n",
    "    response = requests.get('https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd')\n",
    "    price = response.json()['bitcoin']['usd']\n",
    "    \n",
    "    # Initialize the prediction output dictionary\n",
    "    prediction_output = {}\n",
    "\n",
    "    # Load LSTM Model and make prediction\n",
    "    try:\n",
    "        lstm_model = load_model('bitcoin_lstm_model.h5')\n",
    "        \n",
    "        # Preprocess data for LSTM (rescaling)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        price_scaled = scaler.fit_transform(np.array([[price]]))\n",
    "\n",
    "        # Reshape data to match LSTM input (time_step of 60)\n",
    "        time_step = 60\n",
    "        X_input = np.reshape(price_scaled, (1, 1, 1))  # Reshape for single timestep\n",
    "\n",
    "        # LSTM prediction\n",
    "        lstm_prediction = lstm_model.predict(X_input)\n",
    "        lstm_prediction = scaler.inverse_transform(lstm_prediction)  # Rescale back\n",
    "        prediction_output['LSTM_Prediction'] = lstm_prediction[0][0]\n",
    "    except Exception as e:\n",
    "        prediction_output['LSTM_Error'] = str(e)\n",
    "    \n",
    "    # Load ARIMA Model and make prediction\n",
    "    try:\n",
    "        arima_model = sm.tsa.ARIMA.load('bitcoin_arima_model.pkl')\n",
    "        # Use the previous price for ARIMA prediction\n",
    "        df = pd.DataFrame({'Price': [price]})\n",
    "        arima_model_fit = arima_model.fit()\n",
    "        forecast = arima_model_fit.forecast(steps=5)\n",
    "        prediction_output['ARIMA_Forecast'] = forecast\n",
    "    except Exception as e:\n",
    "        prediction_output['ARIMA_Error'] = str(e)\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': prediction_output\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2b0fe5-3b22-442a-a1a1-8518e40ea19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Upload LSTM model\n",
    "s3.upload_file('bitcoin_lstm_model.h5', 'crypto-prediction-project', 'models/bitcoin_lstm_model.h5')\n",
    "\n",
    "# Upload ARIMA model\n",
    "s3.upload_file('bitcoin_arima_model.pkl', 'crypto-prediction-project', 'models/bitcoin_arima_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0035b33a-f0e1-4ab8-8d0d-117f3672af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-west-1:515966506866:model/bitcoin-lstm-model', 'ResponseMetadata': {'RequestId': '080b7af2-892b-461e-9623-22408e3dd166', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '080b7af2-892b-461e-9623-22408e3dd166', 'content-type': 'application/x-amz-json-1.1', 'content-length': '80', 'date': 'Sun, 27 Apr 2025 06:11:41 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()  # Get the SageMaker execution role\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "model_name = 'bitcoin-lstm-model'\n",
    "model_data = 's3://crypto-prediction-project/models/bitcoin_lstm_model.h5'  # S3 path of the model\n",
    "\n",
    "# Specify the pre-built TensorFlow container image\n",
    "tensorflow_inference_image = '763104351884.dkr.ecr.us-west-1.amazonaws.com/tensorflow-inference:2.3.0-cpu'\n",
    "\n",
    "response = sagemaker_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': tensorflow_inference_image,  # Use TensorFlow inference image\n",
    "        'ModelDataUrl': model_data,\n",
    "    },\n",
    "    ExecutionRoleArn=role\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c7d4cb4-c272-4bee-a322-6ab4eee7231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointArn': 'arn:aws:sagemaker:us-west-1:515966506866:endpoint/bitcoin-lstm-endpoint', 'ResponseMetadata': {'RequestId': 'e59d8e41-9f27-4cc1-a08a-fcd4ff023f48', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e59d8e41-9f27-4cc1-a08a-fcd4ff023f48', 'content-type': 'application/x-amz-json-1.1', 'content-length': '89', 'date': 'Sun, 27 Apr 2025 06:12:08 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Create an endpoint configuration\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName='bitcoin-lstm-endpoint-config',\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'InstanceType': 'ml.m5.large',  # Choose instance type\n",
    "            'InitialInstanceCount': 1,\n",
    "            'ModelName': model_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an endpoint\n",
    "endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName='bitcoin-lstm-endpoint',\n",
    "    EndpointConfigName='bitcoin-lstm-endpoint-config'\n",
    ")\n",
    "\n",
    "print(endpoint_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6af8a644-5f06-4e03-96df-4ff1d70ad3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitcoin-lstm-endpoint\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Create a SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# List all endpoints\n",
    "response = sagemaker_client.list_endpoints()\n",
    "\n",
    "# Print the available endpoints\n",
    "for endpoint in response['Endpoints']:\n",
    "    print(endpoint['EndpointName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "877312d3-8a8d-4202-9b7e-107ccb21cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create a SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Specify the endpoint name and model details\n",
    "endpoint_name = \"bitcoin-lstm-endpoint\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27487e30-6b93-4c96-9fca-d3380470c694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.describe_endpoint(EndpointName=\"bitcoin-lstm-endpoint\")\n",
    "print(response['EndpointStatus'])  # Should show 'InService' if the endpoint is healthy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65d2acdd-bb7e-4f07-a05e-11750734ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file bitcoin_lstm_model.h5 compressed into bitcoin_lstm_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# Define the model file and the target tar.gz file\n",
    "model_file = 'bitcoin_lstm_model.h5'\n",
    "tar_gz_file = 'bitcoin_lstm_model.tar.gz'\n",
    "\n",
    "# Create a tar.gz archive\n",
    "with tarfile.open(tar_gz_file, 'w:gz') as tar:\n",
    "    tar.add(model_file, arcname='bitcoin_lstm_model.h5')\n",
    "\n",
    "print(f'Model file {model_file} compressed into {tar_gz_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab6214f8-8da5-4542-bb3d-b11152abda32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to s3://crypto-prediction-project/models/bitcoin_lstm_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Define your S3 bucket and object key\n",
    "bucket_name = 'crypto-prediction-project'\n",
    "object_key = 'models/bitcoin_lstm_model.tar.gz'\n",
    "\n",
    "# Create an S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Upload the file to S3\n",
    "s3_client.upload_file(tar_gz_file, bucket_name, object_key)\n",
    "\n",
    "print(f'File uploaded to s3://{bucket_name}/{object_key}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e07a8-f417-4a18-9668-5e4a62915688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "# Set up SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# Specify the S3 path to your .tar.gz model file\n",
    "model_uri = 's3://crypto-prediction-project/models/bitcoin_lstm_model.tar.gz'\n",
    "\n",
    "# Create a TensorFlow model from the .tar.gz file\n",
    "tensorflow_model = TensorFlowModel(model_data=model_uri,\n",
    "                                   role=role,\n",
    "                                   framework_version='2.3.0',  # Specify the TensorFlow version\n",
    "                                   sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "endpoint = tensorflow_model.deploy(instance_type='ml.m5.large', initial_instance_count=1)\n",
    "\n",
    "print(f'Endpoint created: {endpoint}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774ba83-7ae6-4e7d-8d97-feb275101f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Prepare input data\n",
    "input_data = json.dumps({'price': 50000})  # Example input data\n",
    "\n",
    "# Call the endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(EndpointName=endpoint.endpoint_name,\n",
    "                                             ContentType='application/json',\n",
    "                                             Body=input_data)\n",
    "\n",
    "# Parse the response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(f'Prediction result: {result}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
